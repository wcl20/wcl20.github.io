---
layout: default
---
# Evolving a Behavioral Repertoire for a Walking Robot

## Overview
* Introduce the Transferability-based Behavioral Repertoire Evolution algorithm

## Related Work

### Low Level Controllers
* We distinguish two categories of controllers:
	- un-driven controller always executes the same gait
	- inputs-driven controller can change the robot's movements according to an input
* Walking gait learning has been achieved on legged robots using various contollers:
	- parametrized periodic functions 
	- artificial neural networks with both direct or generative encoding 
	- Central Pattern Generators
	- graph-based genetic programming
* Comparatively few articles deal with controllers able to turn or to change the walking speed according to an input

### Transferability Approach
* Solutions obtained in simulation often do not work well on the real device, because simulation and reality never match perfectly. This phenomenon is called the Reality Gap.
* Transferability approach closes the gap by finding behaviors that act similarly in simulation and in reality.
* During the evolutionary process, a few candidate controllers are transferred to the physical robot to measure the behavioral differences between the simulation and the reality; these differences represent the transferability value of the solutions.
* A regression model is built to predict the transferability value of untested solutions.
* The transferability approach uses a multi-objective optimization algorithm to find solutions that maximize both task-efficiency and the estimated transferability value.

### Novelty Search with Local Competition
* NSLC is based on multi-objective evolutionary algorithms, it combines the exploration abilities of the Novelty Search algorithm with a performance competition between similar individuals.
* The algorithm favors individuals that are new, those that are more efficient than their neighbors and those that are optimal trade-offs between novelty and "local quality".


## Content
* Traditional evolutionary algorithm has failed to be the central of legged robots becaues:
	- most evolved controllers are useless as they can only travel in straight line at a constant speed
	- Evoluationary algorithm requires evaluating the fitness function thousands of times, which is very hard to achieve with a physical robot

### Transferability-based Behavioral Repertoire Evolution
* TBR-Evolution takes inspiration from Novelty Search with Local Competiton
* TBR-Evolution relies on the transferability approach, which combines simulations and tests on the physical robot to find solutions that perform similarly in simulation and in reality
* TBR searches for a repertoire of un-driven controllers, where each controller is able to reach a different point of the space around the robot.
* The transferability approach and novelty search with local competition can be combined because they are both based on multi-objective optimization algorithms.
* A controller is deemed as novel when the controlled individual reaches a region where none, or few of the previously encountered gaits were able to go.
* Each time a controller with a novelty score exceeds a threshold, this controller is saved in an archive.
* Each individual has a quality score and a transferability score:
	- The quality score is set as the angular difference between the arrival orientation and the tangent of the circular trajectory that corresponds to the endpoint
	- The transferability score of a tested controller is computed as the distance between the controller's endpoint reached in simulation and the one reached in reality
* If a controller of the population has better scores than the closest controller in the archive, the one in the archive is replaced by the better one.
	- If the transferability score is lower than a threshold, only the transferability scores are compared, otherwise we compare the quality scores.
* The novelty archive represents the resulting repertoire of controllers

### Genotype of Robot
* The genotype is a set of 24 parameter values defining the angular position of each leg joint with a periodic function $\gamma$ of time $t$, parametrized by an amplitude $\alpha$ and a phase shift $\phi$

$$
\gamma(t, \alpha, \phi) = \alpha \cdot tanh (4 \cdot sin (2 \cdot \pi \cdot (t + \phi)))
$$

* Angular positions are updated and sent to the servos every 30ms.
* The 24 parameters can each have five different values (0, 0.25, 0.5, 0.75, 1)
* For the genotype mutation, each parameter value has a 10% chance of being changed to any value in the set of possible values, with the new value chosen randomly from a uniform distribution over the possible values. 

## Experiment

### Hexapod Robot Simulation
* The goal of this experiment is to show the benefits of evolving simultaneously all the behaviors of the repertoire instead of evolving them separately.
* The virtual robot learns a behavioral repertoire to reach every point in its vicinity.
* As a reference point, we implemented a naive method where the desired endpoints are preselected.
* We compared our resulting archives with archives issued from the Novelty Search algorithm
* For all the experiments we will study the sparseness and the orientation error of the behavioral repertoires generated by each approach
	- The sparseness of the archive is computed by discretizing the Region of Interest (ROI) with a one centimeter grid, and for each point of that grid the distance from the nearest individual of the archive is recorded. The sparseness of the archive is the average of all the recorded distances.
	- The quality of the archive is defined as the average orientation error for all the individuals inside the ROI:
* The area is less covered with the control experiments (nearest and orientation) than with TBR-Evolution.
* TBR-Evolution tends to slightly reduce the exploration abilities of NS and focuses more on the quality of the solutions
* NSLC have a larger orientation error, while TBR-Evolution algorithm consistently leads to very small orientation errors

### Real Hexapod Robot
* The experiment shows how the behavioral repertoire can be learned with a few trials on the physical robot.
* We use the NSGA-II algorithm with the transferability approach to learn a controller that reaches a predefined target as control.
* With the TBR-Evolution algorithm, our physical hexapod robot was able to learn several hundreds of controllers with only 60 transfers of 3 seconds on the robot, which was achieved in 2.5 hours


## Future Work
* Investigate the generation of behavioral repertoires in an environment with obstacles.
* Investigate more sophisticated genotypes and phenotypes like, for instance, neural networks encoded with HyperNEAT 




