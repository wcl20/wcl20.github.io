---
layout: default
---
# Behavioral Repertoire Learning in Robotics

## Overview
* Introduces Behavioral Repertoire Evolution algorithm to produce a collection of diverse but high performing behaviors.

## Related Work
### Learning Low Level Controllers
* Learning low-level sensorimotor behaviors is essential to allow robots to pursue their mission in all situations.
* LLC is the element that drives the agent by sending commands to the motors.
* LLCs are typically combined with high-level controllers, which control the global behavior of the agent using various decision and planning algorithms.
* LLCs can be separated into two categories:
	- Un-driven LLC can command a primitive action such as "stand", "turn left", etc...
	- Inputs-driven LLC can execute parameterized actions such as "turn 30 degrees right"
* One alternative to learning inputs-driven LLCs is to consider a collection of un-driven LLCs.  Thus, a high level algorithm will select the right controller according to the desired action instead of sending the appropriate instruction to an inputs-driven LLC.

### Novelty Search with Local Competition
* Evolutionary algorithms usually converge to a single species of creatures.
* NSLC relies on a multi-objective evolutionary algorithm to combine novelty search with performance competitions between similar individuals.
* In NSLC, two objectives are simultaneously optimized:
	- Novelty: corresponds to the original novelty search algorithm
	- Local competiton objective: compares the performances of each individual to those that share its local niche. This is defined as the number of individuals in the local niche that an individual outperforms according to the performance criterion.
* NSLC thus favors individuals that are new, those that are higher-performing than their neighbors and those that are optimal trade-offs between novelty and "local performance".
* The goal of NSLC is to multitude of creatures that executes the same action.
* In NSLC, local competition is used to optimize primary objective of the individual.
* In NSLC, the archive serves to log all encountered individuals during the evolutionary process and their behaviors to calculate novelty score. 
* In NSLC, only the first encountered individual will be added in the archive. Next individuals executing the same action will not be saved, even if they are more efficient according to another criterion.

## Content

### BR-Evolution
* A new approach to simultaneously learn a large number of un-driven LLCs.
* The method is based on NSLC but with a completely different goal. The goal of BR-Evolution is to generate one creature that executes multitude of actions.
* BR-Evolution uses the novelty objective to explore the space of possible actions. A controller is considered new when its behavioral result is different from results obtained with previous controllers.
* BR-Evolution uses local competiton to promote a secondary objective among the controllers generating the same action.
* In BR-Evolution, the archive constitutes directly the collection of controllers and thus the results of the algorithm.
* During the evolutionary process, if an individual of the population is better than the most similar individual in the archive, the two individuals are swapped.
* At the end of the evolutionary process, the archive contains all the best encountered individuals in all the explored search space.

## Experiment

### Simulated Hexapod Robot
* Evaluate the approach on a simulated hexapod robot with a learning gait task. 
* The aim of this experiment is to obtain a collection of un-driven LLCs that allows the robot to reach every point in its vicinity.
* To get high novelty values, individuals have to follow trajectories leading to endpoints far from the rest of the population.
* For the same number of evaluations, the area is less covered with the control experiments than with the BR-Evolution.
* The more a region is difficult to access, the less we find controllers and the less these controllers have a good orientation.
* Our approach is faster than the control experiments regardless the number of reference points.

## Future Work
* Apply algorithm to real robot using transferability approach
* Investigate the ability of the BR-Evolution to autonomously explore and exploit the abilities of the agent.




